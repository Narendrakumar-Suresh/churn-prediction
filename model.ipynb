{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Churnpredict:\n",
    "    def __init__(self,X,y):\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./final_dataset.csv')\n",
    "\n",
    "X=df.drop(columns=['Churn']).values\n",
    "y=df['Churn'].values\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "batch_size=50\n",
    "learning_rate=0.01\n",
    "dataset = Churnpredict(X, y)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size  # This ensures the split sums up to the total dataset length\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "examples = iter(train_loader)\n",
    "sample, labels = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet,self).__init__()\n",
    "        self.l1=nn.Linear(input_size,hidden_size)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.l2=nn.Linear(hidden_size,hidden_size)\n",
    "        self.relu2=nn.ReLU()\n",
    "        self.l3=nn.Linear(hidden_size,hidden_size)\n",
    "        self.relu3=nn.ReLU()\n",
    "        self.l4=nn.Linear(hidden_size,num_classes)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        # self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out=self.l1(x)\n",
    "        out=self.relu(out)\n",
    "        out=self.l2(out)\n",
    "        out=self.relu2(out)\n",
    "        out=self.l3(out)\n",
    "        out=self.relu3(out)\n",
    "        out=self.l4(out)\n",
    "        out=self.sigmoid(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epcoh1/100, step: 100/113 loss: 0.6641\n",
      "epcoh2/100, step: 100/113 loss: 0.5930\n",
      "epcoh3/100, step: 100/113 loss: 0.6246\n",
      "epcoh4/100, step: 100/113 loss: 0.5671\n",
      "epcoh5/100, step: 100/113 loss: 0.4971\n",
      "epcoh6/100, step: 100/113 loss: 0.5877\n",
      "epcoh7/100, step: 100/113 loss: 0.6288\n",
      "epcoh8/100, step: 100/113 loss: 0.5935\n",
      "epcoh9/100, step: 100/113 loss: 0.6951\n",
      "epcoh10/100, step: 100/113 loss: 0.5732\n",
      "epcoh11/100, step: 100/113 loss: 0.5731\n",
      "epcoh12/100, step: 100/113 loss: 0.6136\n",
      "epcoh13/100, step: 100/113 loss: 0.5934\n",
      "epcoh14/100, step: 100/113 loss: 0.5935\n",
      "epcoh15/100, step: 100/113 loss: 0.6552\n",
      "epcoh16/100, step: 100/113 loss: 0.6748\n",
      "epcoh17/100, step: 100/113 loss: 0.5528\n",
      "epcoh18/100, step: 100/113 loss: 0.6549\n",
      "epcoh19/100, step: 100/113 loss: 0.5935\n",
      "epcoh20/100, step: 100/113 loss: 0.4916\n",
      "epcoh21/100, step: 100/113 loss: 0.6138\n",
      "epcoh22/100, step: 100/113 loss: 0.5732\n",
      "epcoh23/100, step: 100/113 loss: 0.5935\n",
      "epcoh24/100, step: 100/113 loss: 0.5935\n",
      "epcoh25/100, step: 100/113 loss: 0.6752\n",
      "epcoh26/100, step: 100/113 loss: 0.6548\n",
      "epcoh27/100, step: 100/113 loss: 0.5529\n",
      "epcoh28/100, step: 100/113 loss: 0.6341\n",
      "epcoh29/100, step: 100/113 loss: 0.4917\n",
      "epcoh30/100, step: 100/113 loss: 0.5324\n",
      "epcoh31/100, step: 100/113 loss: 0.5936\n",
      "epcoh32/100, step: 100/113 loss: 0.5327\n",
      "epcoh33/100, step: 100/113 loss: 0.4916\n",
      "epcoh34/100, step: 100/113 loss: 0.5526\n",
      "epcoh35/100, step: 100/113 loss: 0.5323\n",
      "epcoh36/100, step: 100/113 loss: 0.4915\n",
      "epcoh37/100, step: 100/113 loss: 0.5529\n",
      "epcoh38/100, step: 100/113 loss: 0.5934\n",
      "epcoh39/100, step: 100/113 loss: 0.5120\n",
      "epcoh40/100, step: 100/113 loss: 0.5526\n",
      "epcoh41/100, step: 100/113 loss: 0.5731\n",
      "epcoh42/100, step: 100/113 loss: 0.6753\n",
      "epcoh43/100, step: 100/113 loss: 0.6345\n",
      "epcoh44/100, step: 100/113 loss: 0.5324\n",
      "epcoh45/100, step: 100/113 loss: 0.6138\n",
      "epcoh46/100, step: 100/113 loss: 0.4924\n",
      "epcoh47/100, step: 100/113 loss: 0.5528\n",
      "epcoh48/100, step: 100/113 loss: 0.6952\n",
      "epcoh49/100, step: 100/113 loss: 0.4920\n",
      "epcoh50/100, step: 100/113 loss: 0.6544\n",
      "epcoh51/100, step: 100/113 loss: 0.5116\n",
      "epcoh52/100, step: 100/113 loss: 0.4512\n",
      "epcoh53/100, step: 100/113 loss: 0.6538\n",
      "epcoh54/100, step: 100/113 loss: 0.5731\n",
      "epcoh55/100, step: 100/113 loss: 0.5731\n",
      "epcoh56/100, step: 100/113 loss: 0.4915\n",
      "epcoh57/100, step: 100/113 loss: 0.5326\n",
      "epcoh58/100, step: 100/113 loss: 0.4917\n",
      "epcoh59/100, step: 100/113 loss: 0.6137\n",
      "epcoh60/100, step: 100/113 loss: 0.5935\n",
      "epcoh61/100, step: 100/113 loss: 0.6542\n",
      "epcoh62/100, step: 100/113 loss: 0.5934\n",
      "epcoh63/100, step: 100/113 loss: 0.6544\n",
      "epcoh64/100, step: 100/113 loss: 0.5324\n",
      "epcoh65/100, step: 100/113 loss: 0.6342\n",
      "epcoh66/100, step: 100/113 loss: 0.6136\n",
      "epcoh67/100, step: 100/113 loss: 0.6140\n",
      "epcoh68/100, step: 100/113 loss: 0.6543\n",
      "epcoh69/100, step: 100/113 loss: 0.6956\n",
      "epcoh70/100, step: 100/113 loss: 0.6547\n",
      "epcoh71/100, step: 100/113 loss: 0.6139\n",
      "epcoh72/100, step: 100/113 loss: 0.5527\n",
      "epcoh73/100, step: 100/113 loss: 0.5528\n",
      "epcoh74/100, step: 100/113 loss: 0.6346\n",
      "epcoh75/100, step: 100/113 loss: 0.5324\n",
      "epcoh76/100, step: 100/113 loss: 0.5529\n",
      "epcoh77/100, step: 100/113 loss: 0.5324\n",
      "epcoh78/100, step: 100/113 loss: 0.5529\n",
      "epcoh79/100, step: 100/113 loss: 0.5935\n",
      "epcoh80/100, step: 100/113 loss: 0.5731\n",
      "epcoh81/100, step: 100/113 loss: 0.6951\n",
      "epcoh82/100, step: 100/113 loss: 0.4515\n",
      "epcoh83/100, step: 100/113 loss: 0.5120\n",
      "epcoh84/100, step: 100/113 loss: 0.5731\n",
      "epcoh85/100, step: 100/113 loss: 0.5526\n",
      "epcoh86/100, step: 100/113 loss: 0.7154\n",
      "epcoh87/100, step: 100/113 loss: 0.5731\n",
      "epcoh88/100, step: 100/113 loss: 0.5731\n",
      "epcoh89/100, step: 100/113 loss: 0.5935\n",
      "epcoh90/100, step: 100/113 loss: 0.6751\n",
      "epcoh91/100, step: 100/113 loss: 0.5526\n",
      "epcoh92/100, step: 100/113 loss: 0.5935\n",
      "epcoh93/100, step: 100/113 loss: 0.7376\n",
      "epcoh94/100, step: 100/113 loss: 0.5325\n",
      "epcoh95/100, step: 100/113 loss: 0.4916\n",
      "epcoh96/100, step: 100/113 loss: 0.5120\n",
      "epcoh97/100, step: 100/113 loss: 0.4316\n",
      "epcoh98/100, step: 100/113 loss: 0.4917\n",
      "epcoh99/100, step: 100/113 loss: 0.5126\n",
      "epcoh100/100, step: 100/113 loss: 0.5731\n"
     ]
    }
   ],
   "source": [
    "input_size=5\n",
    "hidden_size = 50\n",
    "num_classes=1\n",
    "\n",
    "model=NeuralNet(input_size=input_size,hidden_size=hidden_size,num_classes=num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion=nn.BCELoss()\n",
    "optimiser=torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "num_epochs=100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (sample, labels) in enumerate(train_loader):\n",
    "        sample=sample.to(device)\n",
    "        labels = labels.to(device).view(-1, 1)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(sample).to(device)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backward\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"epcoh{epoch + 1}/{num_epochs}, step: {i + 1}/{n_total_steps} loss: {loss.item():.4f}\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.52732434350602\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct=0\n",
    "    n_samples=0\n",
    "\n",
    "    for sample,labels in test_loader:\n",
    "        sample=sample.to(device)\n",
    "        labels=labels.to(device)\n",
    "\n",
    "        output=model(sample)\n",
    "        #value,index\n",
    "        _,predictions=torch.max(output,1)\n",
    "        n_samples +=labels.shape[0]\n",
    "        n_correct +=(predictions==labels).sum().item()\n",
    "acc=100.0 * (n_correct/n_samples)\n",
    "print(f'Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as churn_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.save(model, \"churn_model.pkl\")\n",
    "print(\"Model saved as churn_model.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
