{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Churnpredict:\n",
    "    def __init__(self,X,y):\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./final_dataset.csv')\n",
    "\n",
    "X=df.drop(columns=['Churn']).values\n",
    "y=df['Churn'].values\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "batch_size=50\n",
    "learning_rate=0.01\n",
    "dataset = Churnpredict(X, y)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size  # This ensures the split sums up to the total dataset length\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "examples = iter(train_loader)\n",
    "sample, labels = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet,self).__init__()\n",
    "        self.l1=nn.Linear(input_size,hidden_size)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.l2=nn.Linear(hidden_size,hidden_size)\n",
    "        self.relu2=nn.ReLU()\n",
    "        self.l3=nn.Linear(hidden_size,hidden_size)\n",
    "        self.relu3=nn.ReLU()\n",
    "        self.l4=nn.Linear(hidden_size,num_classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out=self.l1(x)\n",
    "        out=self.relu(out)\n",
    "        out=self.l2(out)\n",
    "        out=self.relu2(out)\n",
    "        out=self.l3(out)\n",
    "        out=self.relu3(out)\n",
    "        out=self.l4(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epcoh1/10, step: 100/113 loss: 0.6519\n",
      "epcoh2/10, step: 100/113 loss: 0.4622\n",
      "epcoh3/10, step: 100/113 loss: 0.4232\n",
      "epcoh4/10, step: 100/113 loss: 0.4343\n",
      "epcoh5/10, step: 100/113 loss: 0.4855\n",
      "epcoh6/10, step: 100/113 loss: 0.6782\n",
      "epcoh7/10, step: 100/113 loss: 0.5972\n",
      "epcoh8/10, step: 100/113 loss: 0.4642\n",
      "epcoh9/10, step: 100/113 loss: 0.6048\n",
      "epcoh10/10, step: 100/113 loss: 0.4636\n"
     ]
    }
   ],
   "source": [
    "input_size=10\n",
    "hidden_size = 100\n",
    "num_classes=1\n",
    "\n",
    "model=NeuralNet(input_size=input_size,hidden_size=hidden_size,num_classes=num_classes)\n",
    "\n",
    "criterion=nn.BCEWithLogitsLoss()\n",
    "optimiser=torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "num_epochs=10\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (sample, labels) in enumerate(train_loader):\n",
    "        sample=sample.to(device)\n",
    "        labels = labels.to(device).view(-1, 1)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(sample)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backward\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"epcoh{epoch + 1}/{num_epochs}, step: {i + 1}/{n_total_steps} loss: {loss.item():.4f}\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.23704755145494\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct=0\n",
    "    n_samples=0\n",
    "\n",
    "    for sample,labels in test_loader:\n",
    "        sample=sample.to(device)\n",
    "        labels=labels.to(device)\n",
    "\n",
    "        output=model(sample)\n",
    "        #value,index\n",
    "        _,predictions=torch.max(output,1)\n",
    "        n_samples +=labels.shape[0]\n",
    "        n_correct +=(predictions==labels).sum().item()\n",
    "acc=100.0 * (n_correct/n_samples)\n",
    "print(f'Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "\n",
    "model.eval()\n",
    "\n",
    "example_input = sample.to(device) \n",
    "\n",
    "onnx_filename = \"churn_model.onnx\"\n",
    "torch.onnx.export(\n",
    "    model,                      \n",
    "    example_input,              \n",
    "    onnx_filename,              \n",
    "    export_params=True,         \n",
    "    opset_version=12,           \n",
    "    do_constant_folding=True,   \n",
    "    input_names=['input'],      \n",
    "    output_names=['output'],    \n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    ")\n",
    "\n",
    "print(f\"Model exported to {onnx_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
